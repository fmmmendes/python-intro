{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d975492c",
   "metadata": {},
   "source": [
    "# Intro to Python and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec02a52",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2541a43-a4fc-4193-9530-1b77791c57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f07be-208a-483e-8dfe-3d61838aaf86",
   "metadata": {},
   "source": [
    "About conventions.. https://www.python.org/dev/peps/pep-0008/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e695f68-fc3b-4616-b70f-37ba2c3ea5e1",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c6ee5d-2f57-4bc8-8f16-767e5045ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n"
     ]
    }
   ],
   "source": [
    "myname = \"John\"\n",
    "print(\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ddbab-5e22-43ec-b93b-e2b4f810dd30",
   "metadata": {},
   "source": [
    "PEP8: \"Function names should be lowercase, with words separated by underscores as necessary to improve readability.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1f4a3f-64e0-486a-9603-ba0a9bf1ac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n"
     ]
    }
   ],
   "source": [
    "my_name = \"John\"\n",
    "print(\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650de7d2",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "* Tuples\n",
    "* Lists\n",
    "* Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7088c0bf-677c-419d-b274-57016485318e",
   "metadata": {},
   "source": [
    "| List                                                                                                           | Tuple                                                                                                | Set                                                                                 | Dictionary                                                                         |   |   |   |   |   |   |\n",
    "|:--------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| List is a non-homogeneous data structure which stores the elements in single row and multiple rows and columns | Tuple is also a non-homogeneous data structure which stores single row and multiple rows and columns | Set data structure is also non-homogeneous data structure but stores in single row  | Dictionary is also a non-homogeneous data structure which stores key value pairs   |   |   |   |   |   |   |\n",
    "| List can be represented by [ ]                                                                                 | Tuple can be represented by  ()                                                                      | Set can be represented by { }                                                       | Dictionary  can be represented by { }                                              |   |   |   |   |   |   |\n",
    "| List allows duplicate elements                                                                                 | Tuple allows duplicate elements                                                                      | Set will not allow duplicate elements                                               | Set will not allow duplicate elements and dictionary doesnâ€™t allow duplicate keys. |   |   |   |   |   |   |\n",
    "| List can use nested among all                                                                                  | Tuple can use nested among all                                                                       | Set can use nested among all                                                        | Dictionary can use nested among all                                                |   |   |   |   |   |   |\n",
    "| Example: [1, 2, 3, 4, 5]                                                                                       | Example: (1, 2, 3, 4, 5)                                                                             | Example: {1, 2, 3, 4, 5}                                                            | Example: {1, 2, 3, 4, 5}                                                           |   |   |   |   |   |   |\n",
    "| List can be created using list() function                                                                      | Tuple can be created using tuple() function.                                                         | Set can be created using set() function                                             | Dictionary can be created using dict() function.                                   |   |   |   |   |   |   |\n",
    "| List is mutable i.e we can make any changes in list.                                                           | Tuple  is immutable i.e we can not make any changes in tuple                                         | Set is mutable i.e we can make any changes in set. But elements are not duplicated. | Dictionary is mutable. But Keys are not duplicated.                                |   |   |   |   |   |   |\n",
    "| List is ordered                                                                                                | Tuple is ordered                                                                                     | Set is unordered                                                                    | Dictionary is ordered                                                              |   |   |   |   |   |   |\n",
    "| Creating an empty list, l=[]                                                                                   | Creating an empty Tuple, t=()                                                                        | Creating a set, a=set()                                                             | Creating an empty dictionary: d={}                                                 |   |   |   |   |   |   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27b42e-135c-484b-9198-97695f0c1966",
   "metadata": {},
   "source": [
    "source: https://www.geeksforgeeks.org/differences-and-applications-of-list-tuple-set-and-dictionary-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea69de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52f7904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = ()\n",
    "type(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626f6ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a',)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = tuple(\"a\")\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b577bb53-c380-42b5-8f18-3c33bacc7f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a',)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = (\"a\",)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27e7a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 'b', 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = tp + tuple((\"b\",3))\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de9e5499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_lst = list(tp)\n",
    "tp_lst.remove('b')\n",
    "tp = tuple(tp_lst)\n",
    "tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046395ba",
   "metadata": {},
   "source": [
    "### Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bcefae1-9cd0-49d6-b6ef-9822f76b311a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Karen Lovelady', 'David Armentrout', 'Mary Mcmillian']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_names = []\n",
    "\n",
    "for x in range(3):\n",
    "    #print(x)\n",
    "    list_names.append(names.get_full_name())\n",
    " \n",
    "list_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "845bbb49-6b33-4b3d-b6dd-3564463eb8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Donald Lane', 'Sandra Jessica', 'Deann Blevins']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_names = [names.get_full_name() for x in range(3)]\n",
    "\n",
    "list_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f73e7",
   "metadata": {},
   "source": [
    "### Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7ea80-cf1d-413d-8dae-bcdd8e54e840",
   "metadata": {},
   "source": [
    "* Serialization (Dictionary to JSON file)\n",
    "* Deserialization (JSON file to Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b6e834-d4c2-4341-9917-81f6e90137db",
   "metadata": {},
   "outputs": [],
   "source": [
    "team = {\n",
    "    1:{\n",
    "        'name':'John',\n",
    "        'age' : 43,\n",
    "        'is_marriage': True\n",
    "    },\n",
    "    2:{\n",
    "        'name':'Anna',\n",
    "        'age' : 39,\n",
    "        'is_marriage': False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c12bbac2-e60f-4102-b15a-573c9dfdf06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'name': 'John', 'age': 43, 'is_marriage': True},\n",
       " 2: {'name': 'Anna', 'age': 39, 'is_marriage': False}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad7324d4-0c5e-4fd6-899f-a49ec9110533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4f64082-42ed-4611-a74c-2cf1d66d4610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'name': 'John', 'age': 43, 'is_marriage': True}, {'name': 'Anna', 'age': 39, 'is_marriage': False}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa4c87ee-71ab-45e3-b247-d270dacb9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, {'name': 'John', 'age': 43, 'is_marriage': True}), (2, {'name': 'Anna', 'age': 39, 'is_marriage': False})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb1e364-c671-488e-9e6c-97afbde77c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team[1]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b688dae-1813-4652-86cd-b6a99f07e8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team.get(1).get('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74979020-f919-4c65-b5a5-b732acc0f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"team.json\" , \"w\" ) as write:\n",
    "    json.dump( team , write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c5b6c-c020-49e6-a261-9a07d482d672",
   "metadata": {},
   "source": [
    "Load a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a71b608-dc92-4f0b-a30d-dd257ce86777",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"team.json\" , ) as read:\n",
    "    team_loaded = json.load(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bbcc69e-f225-481a-aad2-aaaab44f6677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'name': 'John', 'age': 43, 'is_marriage': True},\n",
       " '2': {'name': 'Anna', 'age': 39, 'is_marriage': False}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92811115-b556-44dd-adb2-b19457a95d2b",
   "metadata": {},
   "source": [
    "### Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d3248dd-c7a8-4ccd-8c80-f957e45d1246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Anna', 'John', 'Mary', 'Roger'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = {\"John\",\"Anna\",\"Roger\",\"Anna\",\"Mary\"}\n",
    "\n",
    "print(type(s))\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "853eb41a-8a59-4361-b4bc-5c81f28a5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.add(\"Albert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a04af62-0b48-45e3-8031-e8bddc6f5042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Albert', 'Anna', 'John', 'Mary', 'Roger'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785e9bc",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Example of some funtions declared in the current notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf6b112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from a function\n"
     ]
    }
   ],
   "source": [
    "def hello():\n",
    "    print(\"Hello from a function\") \n",
    "\n",
    "hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "980a8086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subtraction(a,b):\n",
    "    return a - b\n",
    "\n",
    "subtraction(5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6c5bb-bc0b-47bd-ba06-db5b6615e536",
   "metadata": {},
   "source": [
    "Funtions imported from modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9ae8c7f-db00-420a-a056-19023250aa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'md_hello',\n",
       " 'md_subtraction']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modules\n",
    "list_of_funtions = dir(modules)\n",
    "list_of_funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b5ccee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from a function inside a module\n"
     ]
    }
   ],
   "source": [
    "modules.md_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c50484fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "md_subtraction is running\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules.md_subtraction(6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "417c8a38-bee6-445d-9527-bad72e65f992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a Subtraction funtion\\n\\n    Args:\\n        a ([type], optional): [description]. Defaults to float.\\n        b ([type], optional): [description]. Defaults to float.\\n\\n    Returns:\\n        float: [description]\\n    '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules.md_subtraction.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39f24d9-5685-4c1d-af50-62b0445a33af",
   "metadata": {},
   "source": [
    "Use print funtion for a better visualization of documentation built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b43a387-92d0-463c-bba1-5dd52e89865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Subtraction funtion\n",
      "\n",
      "    Args:\n",
      "        a ([type], optional): [description]. Defaults to float.\n",
      "        b ([type], optional): [description]. Defaults to float.\n",
      "\n",
      "    Returns:\n",
      "        float: [description]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(modules.md_subtraction.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e9b96",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Read a csv file into a dataframe on pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6498a530-7828-41f2-b2a9-2ff126cfb2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BooleanDtype',\n",
       " 'Categorical',\n",
       " 'CategoricalDtype',\n",
       " 'CategoricalIndex',\n",
       " 'DataFrame',\n",
       " 'DateOffset',\n",
       " 'DatetimeIndex',\n",
       " 'DatetimeTZDtype',\n",
       " 'ExcelFile',\n",
       " 'ExcelWriter']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_pandas_functions = dir(pd)\n",
    "list_of_pandas_functions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1eaffc1-0483-4aac-8254-c06d64ae269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read_csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a90e8a25-1f66-4361-afed-02cd281bd0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read a comma-separated values (csv) file into DataFrame.\n",
      "\n",
      "Also supports optionally iterating or breaking of the file\n",
      "into chunks.\n",
      "\n",
      "Additional help can be found in the online docs for\n",
      "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "filepath_or_buffer : str, path object or file-like object\n",
      "    Any valid string path is acceptable. The string could be a URL. Valid\n",
      "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "\n",
      "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "\n",
      "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "sep : str, default ','\n",
      "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "    the separator, but the Python parsing engine can, meaning the latter will\n",
      "    be used and automatically detect the separator by Python's builtin sniffer\n",
      "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "    will also force the use of the Python parsing engine. Note that regex\n",
      "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "delimiter : str, default ``None``\n",
      "    Alias for sep.\n",
      "header : int, list of int, default 'infer'\n",
      "    Row number(s) to use as the column names, and the start of the\n",
      "    data.  Default behavior is to infer the column names: if no names\n",
      "    are passed the behavior is identical to ``header=0`` and column\n",
      "    names are inferred from the first line of the file, if column\n",
      "    names are passed explicitly then the behavior is identical to\n",
      "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "    replace existing names. The header can be a list of integers that\n",
      "    specify row locations for a multi-index on the columns\n",
      "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "    skipped (e.g. 2 in this example is skipped). Note that this\n",
      "    parameter ignores commented lines and empty lines if\n",
      "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "    data rather than the first line of the file.\n",
      "names : array-like, optional\n",
      "    List of column names to use. If the file contains a header row,\n",
      "    then you should explicitly pass ``header=0`` to override the column names.\n",
      "    Duplicates in this list are not allowed.\n",
      "index_col : int, str, sequence of int / str, or False, default ``None``\n",
      "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "  string name or column index. If a sequence of int / str is given, a\n",
      "  MultiIndex is used.\n",
      "\n",
      "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "  column as the index, e.g. when you have a malformed file with delimiters at\n",
      "  the end of each line.\n",
      "usecols : list-like or callable, optional\n",
      "    Return a subset of the columns. If list-like, all elements must either\n",
      "    be positional (i.e. integer indices into the document columns) or strings\n",
      "    that correspond to column names provided either by the user in `names` or\n",
      "    inferred from the document header row(s). For example, a valid list-like\n",
      "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "    in ``['foo', 'bar']`` order or\n",
      "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "    for ``['bar', 'foo']`` order.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the column\n",
      "    names, returning names where the callable function evaluates to True. An\n",
      "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "    parsing time and lower memory usage.\n",
      "squeeze : bool, default False\n",
      "    If the parsed data only contains one column then return a Series.\n",
      "prefix : str, optional\n",
      "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "mangle_dupe_cols : bool, default True\n",
      "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "    are duplicate names in the columns.\n",
      "dtype : Type name or dict of column -> type, optional\n",
      "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "    'c': 'Int64'}\n",
      "    Use `str` or `object` together with suitable `na_values` settings\n",
      "    to preserve and not interpret dtype.\n",
      "    If converters are specified, they will be applied INSTEAD\n",
      "    of dtype conversion.\n",
      "engine : {'c', 'python'}, optional\n",
      "    Parser engine to use. The C engine is faster while the python engine is\n",
      "    currently more feature-complete.\n",
      "converters : dict, optional\n",
      "    Dict of functions for converting values in certain columns. Keys can either\n",
      "    be integers or column labels.\n",
      "true_values : list, optional\n",
      "    Values to consider as True.\n",
      "false_values : list, optional\n",
      "    Values to consider as False.\n",
      "skipinitialspace : bool, default False\n",
      "    Skip spaces after delimiter.\n",
      "skiprows : list-like, int or callable, optional\n",
      "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "    at the start of the file.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the row\n",
      "    indices, returning True if the row should be skipped and False otherwise.\n",
      "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "skipfooter : int, default 0\n",
      "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "nrows : int, optional\n",
      "    Number of rows of file to read. Useful for reading pieces of large files.\n",
      "na_values : scalar, str, list-like, or dict, optional\n",
      "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "    per-column NA values.  By default the following values are interpreted as\n",
      "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "    'nan', 'null'.\n",
      "keep_default_na : bool, default True\n",
      "    Whether or not to include the default NaN values when parsing the data.\n",
      "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "\n",
      "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "      is appended to the default NaN values used for parsing.\n",
      "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "      the default NaN values are used for parsing.\n",
      "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "      the NaN values specified `na_values` are used for parsing.\n",
      "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "      strings will be parsed as NaN.\n",
      "\n",
      "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "    `na_values` parameters will be ignored.\n",
      "na_filter : bool, default True\n",
      "    Detect missing value markers (empty strings and the value of na_values). In\n",
      "    data without any NAs, passing na_filter=False can improve the performance\n",
      "    of reading a large file.\n",
      "verbose : bool, default False\n",
      "    Indicate number of NA values placed in non-numeric columns.\n",
      "skip_blank_lines : bool, default True\n",
      "    If True, skip over blank lines rather than interpreting as NaN values.\n",
      "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "    The behavior is as follows:\n",
      "\n",
      "    * boolean. If True -> try parsing the index.\n",
      "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "      each as a separate date column.\n",
      "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "      a single date column.\n",
      "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "      result 'foo'\n",
      "\n",
      "    If a column or index cannot be represented as an array of datetimes,\n",
      "    say because of an unparsable value or a mixture of timezones, the column\n",
      "    or index will be returned unaltered as an object data type. For\n",
      "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "    specify ``date_parser`` to be a partially-applied\n",
      "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "    :ref:`io.csv.mixed_timezones` for more.\n",
      "\n",
      "    Note: A fast-path exists for iso8601-formatted dates.\n",
      "infer_datetime_format : bool, default False\n",
      "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "    format of the datetime strings in the columns, and if it can be inferred,\n",
      "    switch to a faster method of parsing them. In some cases this can increase\n",
      "    the parsing speed by 5-10x.\n",
      "keep_date_col : bool, default False\n",
      "    If True and `parse_dates` specifies combining multiple columns then\n",
      "    keep the original columns.\n",
      "date_parser : function, optional\n",
      "    Function to use for converting a sequence of string columns to an array of\n",
      "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "    string values from the columns defined by `parse_dates` into a single array\n",
      "    and pass that; and 3) call `date_parser` once for each row using one or\n",
      "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "    arguments.\n",
      "dayfirst : bool, default False\n",
      "    DD/MM format dates, international and European format.\n",
      "cache_dates : bool, default True\n",
      "    If True, use a cache of unique, converted dates to apply the datetime\n",
      "    conversion. May produce significant speed-up when parsing duplicate\n",
      "    date strings, especially ones with timezone offsets.\n",
      "\n",
      "    .. versionadded:: 0.25.0\n",
      "iterator : bool, default False\n",
      "    Return TextFileReader object for iteration or getting chunks with\n",
      "    ``get_chunk()``.\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "       ``TextFileReader`` is a context manager.\n",
      "chunksize : int, optional\n",
      "    Return TextFileReader object for iteration.\n",
      "    See the `IO Tools docs\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "    for more information on ``iterator`` and ``chunksize``.\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "       ``TextFileReader`` is a context manager.\n",
      "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      "    For on-the-fly decompression of on-disk data. If 'infer' and\n",
      "    `filepath_or_buffer` is path-like, then detect compression from the\n",
      "    following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
      "    decompression). If using 'zip', the ZIP file must contain only one data\n",
      "    file to be read in. Set to None for no decompression.\n",
      "thousands : str, optional\n",
      "    Thousands separator.\n",
      "decimal : str, default '.'\n",
      "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "lineterminator : str (length 1), optional\n",
      "    Character to break file into lines. Only valid with C parser.\n",
      "quotechar : str (length 1), optional\n",
      "    The character used to denote the start and end of a quoted item. Quoted\n",
      "    items can include the delimiter and it will be ignored.\n",
      "quoting : int or csv.QUOTE_* instance, default 0\n",
      "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "doublequote : bool, default ``True``\n",
      "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "   field as a single ``quotechar`` element.\n",
      "escapechar : str (length 1), optional\n",
      "    One-character string used to escape other characters.\n",
      "comment : str, optional\n",
      "    Indicates remainder of line should not be parsed. If found at the beginning\n",
      "    of a line, the line will be ignored altogether. This parameter must be a\n",
      "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "    fully commented lines are ignored by the parameter `header` but not by\n",
      "    `skiprows`. For example, if ``comment='#'``, parsing\n",
      "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "    treated as the header.\n",
      "encoding : str, optional\n",
      "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "    standard encodings\n",
      "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "       When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
      "       ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
      "       This behavior was previously only the case for ``engine=\"python\"``.\n",
      "\n",
      "    .. versionchanged:: 1.3.0\n",
      "\n",
      "       ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
      "       influence on how encoding errors are handled.\n",
      "\n",
      "encoding_errors : str, optional, default \"strict\"\n",
      "    How encoding errors are treated. `List of possible values\n",
      "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "dialect : str or csv.Dialect, optional\n",
      "    If provided, this parameter will override values (default or not) for the\n",
      "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "    override values, a ParserWarning will be issued. See csv.Dialect\n",
      "    documentation for more details.\n",
      "error_bad_lines : bool, default ``None``\n",
      "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "    default cause an exception to be raised, and no DataFrame will be returned.\n",
      "    If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
      "    returned.\n",
      "\n",
      "    .. deprecated:: 1.3.0\n",
      "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "       encountering a bad line instead.\n",
      "warn_bad_lines : bool, default ``None``\n",
      "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "    \"bad line\" will be output.\n",
      "\n",
      "    .. deprecated:: 1.3.0\n",
      "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "       encountering a bad line instead.\n",
      "on_bad_lines : {'error', 'warn', 'skip'}, default 'error'\n",
      "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "    Allowed values are :\n",
      "\n",
      "        - 'error', raise an Exception when a bad line is encountered.\n",
      "        - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
      "        - 'skip', skip bad lines without raising or warning when they are encountered.\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "delim_whitespace : bool, default False\n",
      "    Specifies whether or not whitespace (e.g. ``' '`` or ``'\t'``) will be\n",
      "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "    is set to True, nothing should be passed in for the ``delimiter``\n",
      "    parameter.\n",
      "low_memory : bool, default True\n",
      "    Internally process the file in chunks, resulting in lower memory use\n",
      "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "    types either set False, or specify the type with the `dtype` parameter.\n",
      "    Note that the entire file is read into a single DataFrame regardless,\n",
      "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "    (Only valid with C parser).\n",
      "memory_map : bool, default False\n",
      "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "    directly onto memory and access the data directly from there. Using this\n",
      "    option can improve performance because there is no longer any I/O overhead.\n",
      "float_precision : str, optional\n",
      "    Specifies which converter the C engine should use for floating-point\n",
      "    values. The options are ``None`` or 'high' for the ordinary converter,\n",
      "    'legacy' for the original lower precision pandas converter, and\n",
      "    'round_trip' for the round-trip converter.\n",
      "\n",
      "    .. versionchanged:: 1.2\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      "    starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      "    ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      "\n",
      "    .. versionadded:: 1.2\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame or TextParser\n",
      "    A comma-separated values (csv) file is returned as two-dimensional\n",
      "    data structure with labeled axes.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47edca40-527e-4efb-84f1-07a3e4c1d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bitcoin_2011-1-2_2022-1-9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb03cc4",
   "metadata": {},
   "source": [
    "Show the first results using the \"head\" method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49dc929d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan-08-2022</td>\n",
       "      <td>36564.243612</td>\n",
       "      <td>37229.038550</td>\n",
       "      <td>35771.261670</td>\n",
       "      <td>36748.872743</td>\n",
       "      <td>7.539408e+10</td>\n",
       "      <td>6.946371e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan-07-2022</td>\n",
       "      <td>37967.058111</td>\n",
       "      <td>37967.058111</td>\n",
       "      <td>36102.961485</td>\n",
       "      <td>36537.631462</td>\n",
       "      <td>7.764271e+10</td>\n",
       "      <td>6.995637e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan-06-2022</td>\n",
       "      <td>38201.660140</td>\n",
       "      <td>38491.911415</td>\n",
       "      <td>37491.009172</td>\n",
       "      <td>37951.276491</td>\n",
       "      <td>9.793463e+10</td>\n",
       "      <td>7.177319e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan-05-2022</td>\n",
       "      <td>40355.401583</td>\n",
       "      <td>41359.168838</td>\n",
       "      <td>37406.449745</td>\n",
       "      <td>38312.722931</td>\n",
       "      <td>9.606402e+10</td>\n",
       "      <td>7.644243e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan-04-2022</td>\n",
       "      <td>40849.626772</td>\n",
       "      <td>41801.873753</td>\n",
       "      <td>40227.324446</td>\n",
       "      <td>40385.241683</td>\n",
       "      <td>6.572451e+10</td>\n",
       "      <td>7.731503e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date          Open          High           Low         Close  \\\n",
       "0  Jan-08-2022  36564.243612  37229.038550  35771.261670  36748.872743   \n",
       "1  Jan-07-2022  37967.058111  37967.058111  36102.961485  36537.631462   \n",
       "2  Jan-06-2022  38201.660140  38491.911415  37491.009172  37951.276491   \n",
       "3  Jan-05-2022  40355.401583  41359.168838  37406.449745  38312.722931   \n",
       "4  Jan-04-2022  40849.626772  41801.873753  40227.324446  40385.241683   \n",
       "\n",
       "         Volume    Market Cap  \n",
       "0  7.539408e+10  6.946371e+11  \n",
       "1  7.764271e+10  6.995637e+11  \n",
       "2  9.793463e+10  7.177319e+11  \n",
       "3  9.606402e+10  7.644243e+11  \n",
       "4  6.572451e+10  7.731503e+11  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f7c64fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           object\n",
       "Open          float64\n",
       "High          float64\n",
       "Low           float64\n",
       "Close         float64\n",
       "Volume        float64\n",
       "Market Cap    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e99f64",
   "metadata": {},
   "source": [
    "### Cleaning approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe196b4d",
   "metadata": {},
   "source": [
    "Normalize column names to lower case, replacing spaces by underscore character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48de5be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'market cap'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4405c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'market_cap'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace(\" \",\"_\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c475cbe",
   "metadata": {},
   "source": [
    "Convert the date format as YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05d5f300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>date_formated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan-08-2022</td>\n",
       "      <td>36564.243612</td>\n",
       "      <td>37229.038550</td>\n",
       "      <td>35771.261670</td>\n",
       "      <td>36748.872743</td>\n",
       "      <td>7.539408e+10</td>\n",
       "      <td>6.946371e+11</td>\n",
       "      <td>2022-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan-07-2022</td>\n",
       "      <td>37967.058111</td>\n",
       "      <td>37967.058111</td>\n",
       "      <td>36102.961485</td>\n",
       "      <td>36537.631462</td>\n",
       "      <td>7.764271e+10</td>\n",
       "      <td>6.995637e+11</td>\n",
       "      <td>2022-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan-06-2022</td>\n",
       "      <td>38201.660140</td>\n",
       "      <td>38491.911415</td>\n",
       "      <td>37491.009172</td>\n",
       "      <td>37951.276491</td>\n",
       "      <td>9.793463e+10</td>\n",
       "      <td>7.177319e+11</td>\n",
       "      <td>2022-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan-05-2022</td>\n",
       "      <td>40355.401583</td>\n",
       "      <td>41359.168838</td>\n",
       "      <td>37406.449745</td>\n",
       "      <td>38312.722931</td>\n",
       "      <td>9.606402e+10</td>\n",
       "      <td>7.644243e+11</td>\n",
       "      <td>2022-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan-04-2022</td>\n",
       "      <td>40849.626772</td>\n",
       "      <td>41801.873753</td>\n",
       "      <td>40227.324446</td>\n",
       "      <td>40385.241683</td>\n",
       "      <td>6.572451e+10</td>\n",
       "      <td>7.731503e+11</td>\n",
       "      <td>2022-01-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date          open          high           low         close  \\\n",
       "0  Jan-08-2022  36564.243612  37229.038550  35771.261670  36748.872743   \n",
       "1  Jan-07-2022  37967.058111  37967.058111  36102.961485  36537.631462   \n",
       "2  Jan-06-2022  38201.660140  38491.911415  37491.009172  37951.276491   \n",
       "3  Jan-05-2022  40355.401583  41359.168838  37406.449745  38312.722931   \n",
       "4  Jan-04-2022  40849.626772  41801.873753  40227.324446  40385.241683   \n",
       "\n",
       "         volume    market_cap date_formated  \n",
       "0  7.539408e+10  6.946371e+11    2022-01-08  \n",
       "1  7.764271e+10  6.995637e+11    2022-01-07  \n",
       "2  9.793463e+10  7.177319e+11    2022-01-06  \n",
       "3  9.606402e+10  7.644243e+11    2022-01-05  \n",
       "4  6.572451e+10  7.731503e+11    2022-01-04  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_formated'] = pd.to_datetime(df.date, infer_datetime_format=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a76a8325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1457.776880\n",
       "1    1864.096626\n",
       "2    1000.902243\n",
       "3    3952.719094\n",
       "4    1574.549307\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = subtraction(df.high, df.low)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c32f2454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1457.7768800240083"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = subtraction(df.high[0], df.low[0])\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e74544-8e47-402e-8f48-b3d86d3b713d",
   "metadata": {},
   "source": [
    "## Plots with Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c4ca90-b5dd-4f7c-a737-16f5f529f840",
   "metadata": {},
   "source": [
    "Plot a time series (data with a date and values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "line, = ax.plot(df.date,df.close, \n",
    "                label = 'BitCoin Close Price by Day')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8836cf-1e61-453e-bcfc-394d17782169",
   "metadata": {},
   "source": [
    "Add the right data types into plots, can make the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbdba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "line, = ax.plot(df['date_formated'], df['close'], \n",
    "                label='BitCoin Close Price by Day')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e1248-60ba-4513-9363-19a43184ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.geeksforgeeks.org/how-to-group-pandas-dataframe-by-date-and-time/\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
    "\n",
    "df_agg = df.groupby(pd.Grouper(key='date_formated', freq='M')).mean()\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe66079-95b6-441b-8bf2-7f406bd97b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    line, = ax.plot(df_agg['date_formated'], df_agg['close'], \n",
    "                    label='BitCoin Close Price')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"Why did fail?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06978b97-b0cc-4960-996d-a53a65b0342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b6a18-4328-488a-9ccf-dd8089791796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac8531-099c-40ba-af66-9725d8a73be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7049cba-e5b5-425e-9953-54498242f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5ebc3-c6d9-4f5c-abf4-9783721855ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "line, = ax.plot(df_agg['date_formated'], df_agg['close'], \n",
    "                label='Mean BitCoin Close Price by Month')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0d36e-7f9c-47d1-8bba-285bb2e04425",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://www.w3schools.com/python/default.asp   \n",
    "https://www.python.org/dev/peps/pep-0008/   \n",
    "https://www.geeksforgeeks.org/how-to-group-pandas-dataframe-by-date-and-time/  \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eab7ff-06cf-4331-906d-01a4c28d408f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
